{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import pipeline, T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_loc = \"/d/hpc/projects/FRI/team9/models/\"\n",
    "tokenizer_type = \"cjvt/t5-sl-small\" # it appears t5-sl-small and large use the same tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paraphraser(model_name, tokenizer_type):\n",
    "    model_loc = models_loc + model_name\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_loc, local_files_only=True)\n",
    "    model = model.to(\"cuda\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(tokenizer_type)\n",
    "    paraphraser = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        framework=\"pt\",\n",
    "        max_length=512,\n",
    "        device=0 # means cuda:0\n",
    "    )\n",
    "    return paraphraser\n",
    "\n",
    "def test_phrases(phrases, paraphraser):\n",
    "    # phrase_pairs = []\n",
    "    for phrase in phrases:\n",
    "        pphrase = paraphraser(phrase)[0][\"generated_text\"]\n",
    "        pphrase = pphrase[0].upper() + pphrase[1:]\n",
    "        # phrase_pairs.append((phrase, pphrase))\n",
    "        \n",
    "        print(f\"{phrase}\\n{pphrase}\\n\\n{'-'*30}\\n\")\n",
    "    # return phrase_pairs\n",
    "\n",
    "def get_latest_model_dir(model_type=None):\n",
    "    dirs = [models_loc + d for d in os.listdir(models_loc) if os.path.isdir(os.path.join(models_loc, d)) and (model_type is None or d.split(\"_\")[0] == model_type)]\n",
    "    if len(dirs) == 0:\n",
    "        raise Exception(\"No models found.\")\n",
    "    latest_loc = max(dirs, key=os.path.getctime)\n",
    "    return latest_loc.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_phrases = [\n",
    "    \"Najbolj je upadla prodaja v segmentu domačih uporabnikov, ki se je skrčil za 65 odstotkov.\",\n",
    "    \"Applova ponudba varčevalnega računa s 4,15-odstotno obrestno mero za svoje uporabnike je naletela na dober odziv. V samo štirih dneh so nabrali približno milijardo dolarjev depozitov.\",\n",
    "    \"V okviru laboratorijskih vaj znanje povežemo s praktično rabo in ga utrdimo z uporabo odprtokodnih sistemov za obdelavo naravnega jezika. Študenti rešujejo naloge, ki temeljijo na realnih raziskovalnih in praktičnih problemih, pretežno v slovenskem in angleškem jeziku.\",\n",
    "    \"Prosim, govorite počasneje.\",\n",
    "    \"Do you speak any other languages?\",\n",
    "    \"V šolskem letu 1994/1995 poskusno izvedli šolsko tekmovanje z nalogami Evropskega matematičnega kenguruja in ga razširili na učence 3. in 4. razreda. V naslednjem letu smo sklenili šolsko tekmovanje z nalogami Evropskega matematičnega kenguruja razširiti še na učence 2. razreda, od šolskega leta 2003/2004 dalje pa so take naloge na voljo za vse razrede osem- in devetletne OŠ.\",\n",
    "    \"Čimprej se pozdravi.\",\n",
    "    \"Pleničke je prala pri mrzlem studenc, en fantič k njej pride, korajžen mladenč.\",\n",
    "    \"Prav milo jo vpraša: Oj deklica ti, zakaj maš tak solzne oči.\",\n",
    "    \"Pleničke je prala pri mrzlem studenc, en fantič k njej pride, korajžen mladenč. Prav milo jo vpraša: Oj deklica ti, zakaj maš tak solzne oči.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latest cjvt/t5-sl-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t5-sl-small_05-09T13:33'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = get_latest_model_dir(\"t5-sl-small\")\n",
    "paraphraser = get_paraphraser(model_name, tokenizer_type)\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najbolj je upadla prodaja v segmentu domačih uporabnikov, ki se je skrčil za 65 odstotkov.\n",
      "Najbolj je upadla prodaja v segmentu domačih uporabnikov, ki se je skrčila za 65 odstotkov.\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Applova ponudba varčevalnega računa s 4,15-odstotno obrestno mero za svoje uporabnike je naletela na dober odziv. V samo štirih dneh so nabrali približno milijardo dolarjev depozitov.\n",
      "Applova ponudba varčevalnega računa s 4,15-odstotno obrestno mero za svoje uporabnike je naletela na dober odziv. V samo štirih dneh so zbrali približno milijardo dolarjev depozitov.\n",
      "\n",
      "------------------------------\n",
      "\n",
      "V okviru laboratorijskih vaj znanje povežemo s praktično rabo in ga utrdimo z uporabo odprtokodnih sistemov za obdelavo naravnega jezika. Študenti rešujejo naloge, ki temeljijo na realnih raziskovalnih in praktičnih problemih, pretežno v slovenskem in angleškem jeziku.\n",
      "V okviru laboratorijskih vaj se znanje povezuje s praktično uporabo in ga utrdimo z uporabo odprtokodnih sistemov za obdelavo naravnega jezika. Študenti rešujejo naloge, ki temeljijo na realnih raziskovalnih in praktičnih problemih, večinoma v slovenskem in angleškem jeziku.\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Prosim, govorite počasneje.\n",
      "Prosim, govorite počasneje.\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Do you speak any other languages?\n",
      "Do you speak any other languages?\n",
      "\n",
      "------------------------------\n",
      "\n",
      "V šolskem letu 1994/1995 poskusno izvedli šolsko tekmovanje z nalogami Evropskega matematičnega kenguruja in ga razširili na učence 3. in 4. razreda. V naslednjem letu smo sklenili šolsko tekmovanje z nalogami Evropskega matematičnega kenguruja razširiti še na učence 2. razreda, od šolskega leta 2003/2004 dalje pa so take naloge na voljo za vse razrede osem- in devetletne OŠ.\n",
      "V šolskem letu 1994 / 1995 smo poskusno izvedli šolsko tekmovanje z nalogami Evropskega matematičnega kenguruja in ga razširili na učence 3. in 4. razreda. V naslednjem letu smo šolsko tekmovanje z nalogami Evropskega matematičnega kenguruja razširili še na učence 2. razreda, od šolskega leta 2003 / 2004 pa so takšne naloge na voljo za vse razrede osem- in devetletne OŠ.\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Čimprej se pozdravi.\n",
      "Čimprej se pozdravi.\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Pleničke je prala pri mrzlem studenc, en fantič k njej pride, korajžen mladenč.\n",
      "Pleničke je prala v vročem studencu, en fant pa jo je prinesel k njej, korajžen fant.\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Prav milo jo vpraša: Oj deklica ti, zakaj maš tak solzne oči.\n",
      "Ona jo je vprašala: Oj, deklica, zakaj imaš tako solzne oči.\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Pleničke je prala pri mrzlem studenc, en fantič k njej pride, korajžen mladenč. Prav milo jo vpraša: Oj deklica ti, zakaj maš tak solzne oči.\n",
      "Pleničke je prala v vročem studencu, en fant pride k njej, korajžen fant. Pomirjeno jo je vprašal: Oj, deklica, zakaj imaš tako solzne oči.\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_phrases(sample_phrases, paraphraser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latest cjvt/t5-sl-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No models found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[43mget_latest_model_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mt5-sl-large\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m paraphraser \u001b[38;5;241m=\u001b[39m get_paraphraser(model_name, tokenizer_type)\n\u001b[1;32m      3\u001b[0m model_name\n",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m, in \u001b[0;36mget_latest_model_dir\u001b[0;34m(model_type)\u001b[0m\n\u001b[1;32m     27\u001b[0m dirs \u001b[38;5;241m=\u001b[39m [models_loc \u001b[38;5;241m+\u001b[39m d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(models_loc) \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(models_loc, d)) \u001b[38;5;129;01mand\u001b[39;00m (model_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m d\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m model_type)]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dirs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo models found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m latest_loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(dirs, key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetctime)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m latest_loc\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mException\u001b[0m: No models found."
     ]
    }
   ],
   "source": [
    "model_name = get_latest_model_dir(\"t5-sl-large\")\n",
    "paraphraser = get_paraphraser(model_name, tokenizer_type)\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrases(sample_phrases, paraphraser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = get_latest_model_dir()\n",
    "paraphraser = get_paraphraser(model_name, tokenizer_type)\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrases(sample_phrases, paraphraser)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
